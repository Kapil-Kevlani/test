{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "sec_key = os.getenv(\"HF_TOKEN\")\n",
    "print(sec_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Access HuggingFace Models with API\n",
    "\n",
    "There are also two ways to use this class. You can specify the model with the repo_id parameter. Those endpoints use the serverless API, which is particularly beneficial to people using pro accounts or enterprise hub. Still, regular users can already have access to a fair amount of request by connecting with their HF token in the environment where they are executing the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "c:\\Users\\admin\\Desktop\\Research Documentation\\conv ai chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=128,temperature=0.7,token=sec_key)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nGenerative AI refers to a type of artificial intelligence (AI) that can create new data that resembles the data it was trained on. This data can be text, images, audio, or even video. Generative AI models are trained on large datasets and use algorithms such as deep learning, generative adversarial networks (GANs), and variational autoencoders (VAEs) to learn the underlying patterns and structures in the data. Once trained, these models can generate new data that is similar in style, form, and content to the original data. Examples of generative AI include text-generating models like ChatGPT, image-generating models like DeepDream, and music-generating models like Amper Music. Generative AI has many applications, including content creation, data augmentation, and personalized recommendations. However, it also raises concerns about the potential for misuse, such as creating deepfakes or generating copyright-infringing content.\\n\\nHow does Generative AI work?\\n\\nGenerative AI works by learning the underlying patterns and structures in a large dataset of examples. This is typically done using deep learning techniques, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs). The model is trained to predict the output for a given input, and during training, it adjusts its internal parameters to minimize the difference between its predicted output and the actual output. Once the model is trained, it can be used to generate new data by providing it with an input and letting it generate an output.\\n\\nOne common approach to generating new data is to use a generative adversarial network (GAN). A GAN consists of two neural networks: a generator network and a discriminator network. The generator network generates new data, and the discriminator network tries to distinguish the generated data from the real data. The two networks are trained together, with the generator network trying to fool the discriminator network, and the discriminator network trying to correctly classify the data as real or fake. Over time, the generator network learns to generate data that is more and more indistinguishable from the real data.\\n\\nAnother common approach is to use a variational autoencoder (VAE). A VAE is a type of neural network that learns to compress and reconstruct data. It consists of an encoder network, which maps the input data to a lower-dimensional latent'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "# Function to capture audio and convert to text\n",
    "def audio_to_text():\n",
    "   # Use the microphone as source for input\n",
    "   with sr.Microphone() as source:\n",
    "       print(\"Adjusting for ambient noise... Please wait.\")\n",
    "       recognizer.adjust_for_ambient_noise(source, duration=2)\n",
    "       print(\"Listening...\")\n",
    "       audio = recognizer.listen(source)\n",
    "       print(\"Processing...\")\n",
    "       try:\n",
    "        #    Recognize speech using Google Web Speech API\n",
    "           text = recognizer.recognize_google(audio)\n",
    "           return text\n",
    "        #    print(\"You said: \" + text)\n",
    "       except sr.UnknownValueError:\n",
    "           print(\"Google Speech Recognition could not understand the audio.\")\n",
    "       except sr.RequestError as e:\n",
    "           print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "# Call the function\n",
    "#audio_to_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting for ambient noise... Please wait.\n",
      "Listening...\n",
      "Processing...\n"
     ]
    }
   ],
   "source": [
    "texttoaudio = audio_to_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital city of India\n"
     ]
    }
   ],
   "source": [
    "print(texttoaudio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm.invoke(texttoaudio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "def text_to_speech(text):\n",
    "   # Initialize the TTS engine\n",
    "   engine = pyttsx3.init()\n",
    "   # Set properties (optional)\n",
    "   rate = engine.getProperty('rate')   # Speed of speech\n",
    "   engine.setProperty('rate', rate-50)  # Reduce the rate\n",
    "   volume = engine.getProperty('volume')  # Volume level (0.0 to 1.0)\n",
    "   engine.setProperty('volume', volume + 0.25)  # Increase the volume\n",
    "   # Pass the text to the engine\n",
    "   engine.say(text)\n",
    "   # Run and wait method to process the voice commands\n",
    "   engine.runAndWait()\n",
    "# Example usage\n",
    "text_to_speech(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
